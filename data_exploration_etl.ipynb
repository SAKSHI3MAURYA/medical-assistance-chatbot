{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Sw7w-H842qwa",
        "outputId": "ea16d467-c6f7-40a1-bee4-f9f4e71a6f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "\n",
        "# Define paths to your data on Google Drive (replace with your actual paths)\n",
        "all_doc_data_path = \"/content/drive/My Drive/ai_medical_assistant/data/all_doctors_data.csv\"\n",
        "disease_symp_path = \"/content/drive/My Drive/ai_medical_assistant/data/disease-symp.csv\"\n",
        "medical_chatbot_qa_path = \"/content/drive/My Drive/ai_medical_assistant/data/medical_chatbot_qa.csv\"\n",
        "medical_book_path = \"/content/drive/My Drive/ai_medical_assistant/data/Medical_book.pdf\"\n",
        "\n",
        "output_path = \"/content/drive/My Drive/ai_medical_assistant/cleaned_data/\"\n",
        "os.makedirs(output_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "a5iz6dUH3ROH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunk size (adjust based on available RAM)\n",
        "chunk_size = 1000\n",
        "\n",
        "# Initialize an empty list to store cleaned chunks\n",
        "cleaned_chunks = []\n",
        "\n",
        "# Iterate over the CSV file in chunks\n",
        "for chunk in pd.read_csv(all_doc_data_path, chunksize=chunk_size):\n",
        "    # Data Cleaning and Transformation\n",
        "    # Handle missing values (e.g., fill with \"Unknown\" or drop the row)\n",
        "    chunk.fillna(\"Unknown\", inplace=True)\n",
        "    # Standardize column names (e.g., lowercase, replace spaces)\n",
        "    chunk.columns = chunk.columns.str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "    #Data type optimizations\n",
        "    for col in chunk.columns:\n",
        "      if chunk[col].dtype == 'object': #check type\n",
        "        num_unique_values = len(chunk[col].unique())\n",
        "        num_total_values = len(chunk[col])\n",
        "        if (num_unique_values / num_total_values) < 0.5: #if unique values are less than 50% of total values\n",
        "          chunk[col] = chunk[col].astype('category') #convert type to category\n",
        "\n",
        "    #Potentially standardize state names\n",
        "    #chunk['state'] = chunk['state'].apply(standardize_state_name) #example transformation, assuming you have this function\n",
        "\n",
        "    # Append the cleaned chunk to the list\n",
        "    cleaned_chunks.append(chunk)\n",
        "\n",
        "# Concatenate all cleaned chunks into a single DataFrame\n",
        "all_doc_data_cleaned = pd.concat(cleaned_chunks, ignore_index=True)\n",
        "\n",
        "# Save the cleaned data to a new CSV file\n",
        "all_doc_data_cleaned.to_csv(os.path.join(output_path, \"all_doc_data_cleaned.csv\"), index=False)\n",
        "\n",
        "# Free up memory\n",
        "del cleaned_chunks\n",
        "del all_doc_data_cleaned\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "print(\"all_doc_data_cleaned.csv process done \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUblQBpB3YW8",
        "outputId": "7a4098fe-a1bb-48a7-e0fd-5943b958ed08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all_doc_data_cleaned.csv process done \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Chunk size (adjust based on available RAM)\n",
        "chunk_size = 1000\n",
        "\n",
        "# Initialize an empty list to store cleaned chunks\n",
        "cleaned_chunks = []\n",
        "\n",
        "# Iterate over the CSV file in chunks\n",
        "for chunk in pd.read_csv(disease_symp_path, chunksize=chunk_size):\n",
        "\n",
        "    # Data Cleaning and Transformation\n",
        "    chunk.fillna(\"Unknown\", inplace=True)\n",
        "    chunk.columns = chunk.columns.str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "    #More advanced text cleaning - lowercase\n",
        "    chunk['diseases'] = chunk['diseases'].str.lower()\n",
        "    chunk['descriptions'] = chunk['descriptions'].str.lower()\n",
        "\n",
        "    cleaned_chunks.append(chunk)\n",
        "\n",
        "# Concatenate all cleaned chunks into a single DataFrame\n",
        "disease_symp_cleaned = pd.concat(cleaned_chunks, ignore_index=True)\n",
        "\n",
        "disease_symp_cleaned.to_csv(os.path.join(output_path, \"disease_symp_cleaned.csv\"), index=False)\n",
        "\n",
        "# Free up memory\n",
        "del cleaned_chunks\n",
        "del disease_symp_cleaned\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "print(\"disease_symp_cleaned.csv process done \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uzJwM0x3gJv",
        "outputId": "45318ce4-1a85-4bc4-bee7-e158e0fb66bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disease_symp_cleaned.csv process done \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Chunk size (adjust based on available RAM)\n",
        "chunk_size = 1000\n",
        "\n",
        "# Initialize an empty list to store cleaned chunks\n",
        "cleaned_chunks = []\n",
        "\n",
        "# Iterate over the CSV file in chunks\n",
        "for chunk in pd.read_csv(medical_chatbot_qa_path, chunksize=chunk_size):\n",
        "    # Data Cleaning and Transformation\n",
        "    chunk.fillna(\"Unknown\", inplace=True)\n",
        "    chunk.columns = chunk.columns.str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "    #Text cleaning - remove punctuation, lowercase\n",
        "    chunk['description'] = chunk['description'].str.lower().str.replace(r'[^\\w\\s]+', '', regex=True)\n",
        "    chunk['patient'] = chunk['patient'].str.lower().str.replace(r'[^\\w\\s]+', '', regex=True)\n",
        "    chunk['doctor'] = chunk['doctor'].str.lower().str.replace(r'[^\\w\\s]+', '', regex=True)\n",
        "\n",
        "    cleaned_chunks.append(chunk)\n",
        "\n",
        "# Concatenate all cleaned chunks into a single DataFrame\n",
        "medical_chatbot_qa_cleaned = pd.concat(cleaned_chunks, ignore_index=True)\n",
        "\n",
        "medical_chatbot_qa_cleaned.to_csv(os.path.join(output_path, \"medical_chatbot_qa_cleaned.csv\"), index=False)\n",
        "\n",
        "# Free up memory\n",
        "del cleaned_chunks\n",
        "del medical_chatbot_qa_cleaned\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "print(\"medical_chatbot_qa_cleaned.csv process done \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5worP_013jOu",
        "outputId": "0973ce67-1b74-4b51-d21e-336be4846fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "medical_chatbot_qa_cleaned.csv process done \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2 #if you dont have it installed\n",
        "\n",
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "  \"\"\"Extracts text from a PDF file.\"\"\"\n",
        "  text = \"\"\n",
        "  try:\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "      reader = PyPDF2.PdfReader(file)\n",
        "      for page_num in range(len(reader.pages)):\n",
        "        page = reader.pages[page_num]\n",
        "        text += page.extract_text()\n",
        "  except Exception as e:\n",
        "    print(f\"Error extracting text from PDF: {e}\")\n",
        "    return None\n",
        "  return text\n",
        "\n",
        "\n",
        "medical_book_text = extract_text_from_pdf(medical_book_path)\n",
        "\n",
        "if medical_book_text:\n",
        "  #Basic cleaning\n",
        "  medical_book_text = medical_book_text.lower()\n",
        "  # You'll likely need more sophisticated cleaning here (e.g., remove headers/footers, split into sections)\n",
        "  #Depending on the size, may need to chunk and save to multiple text files\n",
        "\n",
        "  with open(os.path.join(output_path, \"medical_book_cleaned.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(medical_book_text)\n",
        "\n",
        "  del medical_book_text\n",
        "  import gc\n",
        "  gc.collect()\n",
        "\n",
        "  print(\"medical_book_cleaned.text process done \")\n",
        "\n",
        "else:\n",
        "  print(\"Could not extract text from Medical_book.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnkIcaIE3lcX",
        "outputId": "83e49ed2-5be1-4571-ab3d-46040c6fb6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "medical_book_cleaned.text process done \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install weaviate-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2tuIqSK3n9r",
        "outputId": "ba6d8350-ff22-486a-d5e2-6b57e8610010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: weaviate-client in /usr/local/lib/python3.11/dist-packages (4.11.1)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (0.28.1)\n",
            "Requirement already satisfied: validators==0.34.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (0.34.0)\n",
            "Requirement already satisfied: authlib<1.3.2,>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (1.3.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (2.10.6)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.66.2 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (1.70.0)\n",
            "Requirement already satisfied: grpcio-tools<2.0.0,>=1.66.2 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (1.70.0)\n",
            "Requirement already satisfied: grpcio-health-checking<2.0.0,>=1.66.2 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (1.70.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<1.3.2,>=1.2.1->weaviate-client) (43.0.3)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.11/dist-packages (from grpcio-health-checking<2.0.0,>=1.66.2->weaviate-client) (5.29.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from grpcio-tools<2.0.0,>=1.66.2->weaviate-client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.26.0->weaviate-client) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (4.12.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.26.0->weaviate-client) (1.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['WEAVIATE_URL'] = 'https://oxgymtteqrxaf03sexsa.c0.us-east1.gcp.weaviate.cloud'\n",
        "os.environ['WEAVIATE_API_KEY'] = 'OYuEkc5LrUA708D2vtrYJEl0NWUcK4ZMDwnP'"
      ],
      "metadata": {
        "id": "cctiD-5X4NDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import weaviate\n",
        "print(f\"Weaviate version: {weaviate.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOoj2wAj6zaT",
        "outputId": "25aad80a-fbcc-49f2-b155-1a03290d1458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weaviate version: 4.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from weaviate.classes.init import Auth\n",
        "\n",
        "# Set environment variables\n",
        "WEAVIATE_URL = os.environ[\"WEAVIATE_URL\"]\n",
        "WEAVIATE_API_KEY = os.environ[\"WEAVIATE_API_KEY\"]\n",
        "\n",
        "# Authenticate with the Weaviate cluster\n",
        "auth_config = weaviate.AuthApiKey(api_key=os.environ[\"WEAVIATE_API_KEY\"])\n",
        "\n",
        "# Instantiate the client with the auth config and cluster URL\n",
        "client = weaviate.connect_to_weaviate_cloud(\n",
        "    cluster_url=WEAVIATE_URL,                                    # Replace with your Weaviate Cloud URL\n",
        "    auth_credentials=Auth.api_key(WEAVIATE_API_KEY),             # Replace with your Weaviate Cloud key\n",
        ")\n",
        "# 4. Test connection\n",
        "print(client.is_ready())\n",
        "\n",
        "class_name = \"Doctor\"\n",
        "class_properties = [\n",
        "    {\"name\": \"name\", \"dataType\": [\"text\"]},\n",
        "    {\"name\": \"specialization\", \"dataType\": [\"text\"]},\n",
        "    {\"name\": \"experience\", \"dataType\": [\"int\"]},\n",
        "    {\"name\": \"location\", \"dataType\": [\"geoCoordinates\"]},\n",
        "    {\"name\": \"consultation_fee\", \"dataType\": [\"number\"]}\n",
        "]\n",
        "\n",
        "class_obj = {\n",
        "    \"class\": class_name,\n",
        "    \"properties\": class_properties,\n",
        "      \"vectorizerConfig\": {\n",
        "        \"text2vec-transformers\": {\n",
        "            \"vectorizeClassName\": False,\n",
        "            \"vectorizePropertyName\": False\n",
        "        }\n",
        "    },\n",
        "    \"description\": \"Collection to store Doctor information\"\n",
        "}\n",
        "\n",
        "# Get all collection\n",
        "col_configs = client.collections.list_all()\n",
        "\n",
        "# Print all collection names\n",
        "for name in col_configs:\n",
        "    print(name)\n",
        "\n",
        "# # Print one collection configuration\n",
        "print(col_configs[\"Doctor\"])\n",
        "print(col_configs[\"Doctor\"].properties)        # property schema\n",
        "print(col_configs[\"Doctor\"].vectorizer_config) # vectorizer configuration\n",
        "print(col_configs[\"Doctor\"].vectorizer)\n",
        "\n",
        "# # Create the Doctor class in Weaviate\n",
        "# try:\n",
        "#     client.schema.create_class(class_obj)\n",
        "#     print(\"Doctor class created successfully.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error creating Doctor class: {e}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CyAu0A5-4cgm",
        "outputId": "051a82f8-eff1-4d6f-b93d-e9135be0ca72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Doctor\n",
            "Disease\n",
            "_CollectionConfigSimple(name='Doctor', description=None, generative_config=_GenerativeConfig(generative=<GenerativeSearches.COHERE: 'generative-cohere'>, model={}), properties=[_Property(name='properties', description=\"This property was generated by Weaviate's auto-schema feature on Sun Mar  2 17:36:47 2025\", data_type=<DataType.OBJECT_ARRAY: 'object[]'>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=[_NestedProperty(data_type=<DataType.TEXT_ARRAY: 'text[]'>, description=\"This nested property was generated by Weaviate's auto-schema feature on Sun Mar  2 17:36:47 2025\", index_filterable=True, index_searchable=True, name='dataType', nested_properties=None, tokenization=<Tokenization.WORD: 'word'>), _NestedProperty(data_type=<DataType.TEXT: 'text'>, description=\"This nested property was generated by Weaviate's auto-schema feature on Sun Mar  2 17:36:47 2025\", index_filterable=True, index_searchable=True, name='name', nested_properties=None, tokenization=<Tokenization.WORD: 'word'>)], tokenization=None, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-weaviate'), _Property(name='class', description=\"This property was generated by Weaviate's auto-schema feature on Sun Mar  2 17:36:47 2025\", data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-weaviate'), _Property(name='description', description=\"This property was generated by Weaviate's auto-schema feature on Sun Mar  2 17:36:47 2025\", data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-weaviate')], references=[], reranker_config=None, vectorizer_config=_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_WEAVIATE: 'text2vec-weaviate'>, model={'baseUrl': 'https://api.embedding.weaviate.io', 'model': 'Snowflake/snowflake-arctic-embed-l-v2.0', 'truncate': 'right'}, vectorize_collection_name=True), vectorizer=<Vectorizers.TEXT2VEC_WEAVIATE: 'text2vec-weaviate'>, vector_config=None)\n",
            "[_Property(name='properties', description=\"This property was generated by Weaviate's auto-schema feature on Sun Mar  2 17:36:47 2025\", data_type=<DataType.OBJECT_ARRAY: 'object[]'>, index_filterable=True, index_range_filters=False, index_searchable=False, nested_properties=[_NestedProperty(data_type=<DataType.TEXT_ARRAY: 'text[]'>, description=\"This nested property was generated by Weaviate's auto-schema feature on Sun Mar  2 17:36:47 2025\", index_filterable=True, index_searchable=True, name='dataType', nested_properties=None, tokenization=<Tokenization.WORD: 'word'>), _NestedProperty(data_type=<DataType.TEXT: 'text'>, description=\"This nested property was generated by Weaviate's auto-schema feature on Sun Mar  2 17:36:47 2025\", index_filterable=True, index_searchable=True, name='name', nested_properties=None, tokenization=<Tokenization.WORD: 'word'>)], tokenization=None, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-weaviate'), _Property(name='class', description=\"This property was generated by Weaviate's auto-schema feature on Sun Mar  2 17:36:47 2025\", data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-weaviate'), _Property(name='description', description=\"This property was generated by Weaviate's auto-schema feature on Sun Mar  2 17:36:47 2025\", data_type=<DataType.TEXT: 'text'>, index_filterable=True, index_range_filters=False, index_searchable=True, nested_properties=None, tokenization=<Tokenization.WORD: 'word'>, vectorizer_config=_PropertyVectorizerConfig(skip=False, vectorize_property_name=False), vectorizer='text2vec-weaviate')]\n",
            "_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_WEAVIATE: 'text2vec-weaviate'>, model={'baseUrl': 'https://api.embedding.weaviate.io', 'model': 'Snowflake/snowflake-arctic-embed-l-v2.0', 'truncate': 'right'}, vectorize_collection_name=True)\n",
            "Vectorizers.TEXT2VEC_WEAVIATE\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import os\n",
        "from weaviate.classes.init import Auth\n",
        "\n",
        "# Set environment variables\n",
        "WEAVIATE_URL = os.environ[\"WEAVIATE_URL\"]\n",
        "WEAVIATE_API_KEY = os.environ[\"WEAVIATE_API_KEY\"]\n",
        "\n",
        "# Authenticate with the Weaviate cluster\n",
        "auth_config = weaviate.AuthApiKey(api_key=os.environ[\"WEAVIATE_API_KEY\"])\n",
        "\n",
        "# Instantiate the client with the auth config and cluster URL\n",
        "client = weaviate.connect_to_weaviate_cloud(\n",
        "    cluster_url=WEAVIATE_URL,                                    # Replace with your Weaviate Cloud URL\n",
        "    auth_credentials=Auth.api_key(WEAVIATE_API_KEY),             # Replace with your Weaviate Cloud key\n",
        ")\n",
        "# 4. Test connection\n",
        "print(client.is_ready())\n",
        "\n",
        "\n",
        "class_name = \"Disease\"\n",
        "class_properties = [\n",
        "    {\"name\": \"name\", \"dataType\": [\"text\"]},\n",
        "    {\"name\": \"description\", \"dataType\": [\"text\"]}\n",
        "]\n",
        "\n",
        "class_obj = {\n",
        "    \"class\": class_name,\n",
        "    \"properties\": class_properties,\n",
        "      \"vectorizerConfig\": {\n",
        "        \"text2vec-transformers\": {\n",
        "            \"vectorizeClassName\": False,\n",
        "            \"vectorizePropertyName\": False\n",
        "        }\n",
        "    },\n",
        "    \"description\": \"Collection to store Disease information\"\n",
        "}\n",
        "\n",
        "# Get all collection\n",
        "col_configs = client.collections.list_all()\n",
        "\n",
        "# Print all collection names\n",
        "for name in col_configs:\n",
        "    print(name)\n",
        "\n",
        "# Print information about the Disease collection\n",
        "print(col_configs[\"Disease\"])\n",
        "print(col_configs[\"Disease\"].properties)        # property schema\n",
        "print(col_configs[\"Disease\"].vectorizer_config) # vectorizer configuration\n",
        "print(col_configs[\"Disease\"].vectorizer)\n",
        "\n",
        "# # Create the Disease class in Weaviate (commented out to avoid errors)\n",
        "# try:\n",
        "#     client.schema.create_class(class_obj)\n",
        "#     print(\"Disease class created successfully.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error creating Disease class: {e}\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0P84K56yRTX",
        "outputId": "f88b1990-413f-463e-868b-16c09283ff4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Doctor\n",
            "Disease\n",
            "_CollectionConfigSimple(name='Disease', description=None, generative_config=_GenerativeConfig(generative=<GenerativeSearches.COHERE: 'generative-cohere'>, model={}), properties=[], references=[], reranker_config=None, vectorizer_config=_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_WEAVIATE: 'text2vec-weaviate'>, model={'baseUrl': 'https://api.embedding.weaviate.io', 'model': 'Snowflake/snowflake-arctic-embed-l-v2.0', 'truncate': 'right'}, vectorize_collection_name=True), vectorizer=<Vectorizers.TEXT2VEC_WEAVIATE: 'text2vec-weaviate'>, vector_config=None)\n",
            "[]\n",
            "_VectorizerConfig(vectorizer=<Vectorizers.TEXT2VEC_WEAVIATE: 'text2vec-weaviate'>, model={'baseUrl': 'https://api.embedding.weaviate.io', 'model': 'Snowflake/snowflake-arctic-embed-l-v2.0', 'truncate': 'right'}, vectorize_collection_name=True)\n",
            "Vectorizers.TEXT2VEC_WEAVIATE\n"
          ]
        }
      ]
    }
  ]
}